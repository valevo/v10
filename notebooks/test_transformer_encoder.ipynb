{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Embedding, Linear, Softmax, NLLLoss, RNN, ELU\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLoop:\n",
    "    def __init__(self, model):\n",
    "        self.criterion = NLLLoss()\n",
    "        self.optimiser = SGD(lm.parameters(), lr=0.1) # 0.01\n",
    "        self.model = model\n",
    "        \n",
    "        self.losses = []\n",
    "        self.i = 0\n",
    "\n",
    "    def train(self, n, train_in, train_out, eval_out=None, verbose=0):\n",
    "        self.model.train()\n",
    "        self.train_data = train_in\n",
    "        \n",
    "#         if train_out is None: train_out = train_in\n",
    "        if eval_out is None: eval_out = train_in\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(n)):  # , initial=self.i, total=n):\n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            predicted = self.model(train_in)\n",
    "            \n",
    "            \n",
    "#             loss = 0\n",
    "#             for pred_row, true_row in zip(predicted, train_out):\n",
    "#                 loss += self.criterion(pred_row, true_row)\n",
    "            \n",
    "            loss = self.criterion(predicted.flatten(0,1), train_out.flatten(0,1))\n",
    "            loss.backward()\n",
    "            self.optimiser.step()\n",
    "        \n",
    "            self.losses.append(loss.detach().item())\n",
    "            \n",
    "            if verbose and i and i % verbose == 0:\n",
    "                self.eval_with(eval_out)\n",
    "        \n",
    "        self.i = i\n",
    "        if verbose: self.show()\n",
    "            \n",
    "    def show(self):\n",
    "        plt.plot(range(len(self.losses)), self.losses, \"--\")\n",
    "        \n",
    "        \n",
    "    def eval_with(self, test=None, average=True):\n",
    "        if test is None: test = self.train_data\n",
    "        n, k = test.shape\n",
    "        acc = (test == lm(test).argmax(-1)).sum()/(n*k)\n",
    "        print(\"Accuracy: \", round(acc.item(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pure LM -- TransformerEncoder which Learns to Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(torch.nn.Module):\n",
    "    def __init__(self, vocab_dim, embed_dim=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.emb = Embedding(vocab_dim, self.embed_dim)\n",
    "        \n",
    "        # nhead needs to divide d_model (embedding dimension)\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=self.embed_dim, nhead=self.embed_dim//2)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x)\n",
    "        out = self.encoder(x_emb)\n",
    "#         out_p = self.sigma(self.linear(out))\n",
    "        return out  # output shape is (x.shape[0], x.shape[1], self.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, lm, out_dim):\n",
    "        super().__init__()\n",
    "        self.lm = lm\n",
    "        self.in_dim = lm.embed_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.linear = Linear(in_features=self.in_dim, out_features=self.out_dim)\n",
    "    \n",
    "    def forward(self, lm_input):\n",
    "        return self.linear(lm(lm_input))\n",
    "    \n",
    "class ReconstructHead(Head):\n",
    "    def __init__(self, lm):\n",
    "        super().__init__(lm, out_dim=lm.vocab_dim)\n",
    "        self.sigma = Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, lm_input):\n",
    "        # required to fan back out to vocabulary dimensionality from embedding dimensionality\n",
    "        back_projection = super().forward(lm_input)\n",
    "        return self.sigma(back_projection)\n",
    "    \n",
    "    \n",
    "class RNNHead(Head):\n",
    "    def __init__(self, lm):\n",
    "        super().__init__(lm, out_dim=1)\n",
    "        \n",
    "        self.h = 4\n",
    "        self.rnn = RNN(input_size=self.in_dim, hidden_size=self.h,\n",
    "                        num_layers=1, bidirectional=False,\n",
    "                        batch_first=True, dropout=0.1)\n",
    "        self.linear = Linear(in_features=self.h, out_features=self.out_dim)\n",
    "        self.elu = ELU()\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate_hidden_layers(rnn_hidden, method=\"concat\"):\n",
    "        # shape of rnn_hidden: (num_layers * num_directions, batch, hidden_size)\n",
    "        if method == \"concat\":\n",
    "            return rnn_hidden.transpose(1,0).flatten(1,2)\n",
    "        elif method == \"sum\":\n",
    "            return rnn_hidden.transpose(1,0).sum(-1)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    \n",
    "    \n",
    "    def forward(self, lm_input):\n",
    "        lm_out = lm(lm_input)\n",
    "        \n",
    "        rnn_out, rnn_hidden = self.rnn(lm_out)\n",
    "#         print(rnn_hidden.shape)\n",
    "        hidden_vec = self.aggregate_hidden_layers(rnn_hidden, method=\"concat\")\n",
    "#         print(rnn_out.shape, hidden_vec.shape)\n",
    "        return self.elu(self.linear(hidden_vec))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy test data\n",
    "n, k, V = 100, 4, 6\n",
    "vecs = torch.randint(V, size=(n, k))\n",
    "sums = vecs.sum(-1).reshape(-1, 1)\n",
    "sorts = vecs.sort(-1)[0]\n",
    "remainders = vecs.remainder(5)\n",
    "reverses = vecs.flip((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM(V, embed_dim=100)\n",
    "\n",
    "sort_head = ReconstructHead(lm)\n",
    "rnn_head = RNNHead(lm)\n",
    "\n",
    "trainer = TrainLoop(rnn_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train(1000, train_in=vecs, train_out=sums, verbose=0)\n",
    "print()\n",
    "trainer.eval_with(torch.randint(V, size=(100, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vecs = torch.randint(V, size=(3, k))\n",
    "\n",
    "eval_vecs, sort_head(eval_vecs).argmax(-1), eval_vecs.flip((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_sorted = (vecs == sorts).sum(-1) == k\n",
    "is_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to Try\n",
    "\n",
    " - implement transformer heads: sum of vector, sort/reverse vector\n",
    " \n",
    "\n",
    " - Postional Encodings (see [pytorch tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html))\n",
    " - Masking Attention (see [pytorch tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)) <br>\n",
    "   -> potentially has effect equivalent to skip-grams\n",
    "   \n",
    "   \n",
    " - extract embeddings (of vocabulary, of vector) from LM <br>\n",
    "   e.g. something along the lines of `list(lm.emb.parameters())[0].detach()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV: RNN Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(batch_size, train_in, train_out, shuffle=False):\n",
    "    if shuffle:\n",
    "        pass\n",
    "    \n",
    "    cur = 0\n",
    "    batch_in, batch_out = train_in[cur:cur+batch_size], train_out[cur:cur+batch_size]\n",
    "    yield batch_in, batch_out\n",
    "    \n",
    "    while batch_in.shape[0] == batch_size:\n",
    "        cur += batch_size\n",
    "        batch_in, batch_out = train_in[cur:cur+batch_size], train_out[cur:cur+batch_size]\n",
    "        if batch_in.numel() > 0:\n",
    "            yield batch_in, batch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = vecs; train_out = sums.float()\n",
    "eval_in = torch.randint(V, size=(10, k)); eval_out = eval_in.sum(-1).reshape(-1, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM(V, embed_dim=10)\n",
    "rnn_head = RNNHead(lm)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_head.train()\n",
    "\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = L1Loss(reduction=\"sum\")\n",
    "optimiser = SGD(lm.parameters(), lr=0.01)\n",
    "# optimiser = Adam(lm.parameters(), lr=0.1)\n",
    "        \n",
    "    \n",
    "for i in tqdm(range(500)):\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "#     predicted = rnn_head(train_in)\n",
    "    \n",
    "    loss = 0\n",
    "    for batch_in, batch_out in iter_batches(90, train_in, train_out):\n",
    "        \n",
    "        sum_pred = rnn_head(batch_in)\n",
    "        loss += criterion(sum_pred, batch_out)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    losses.append(loss.detach().item())\n",
    "        \n",
    "            \n",
    "#     loss = criterion(predicted, train_out)\n",
    "    \n",
    "# #     print(predicted.dtype, loss.dtype, train_out.dtype)\n",
    "#     loss.backward()\n",
    "#     optimiser.step()\n",
    "        \n",
    "#     losses.append(loss.detach().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)), losses, \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_in, rnn_head(eval_in), eval_out, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Using Huggingface's transformers library (BERT, GPT-2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BertConfig()\n",
    "\n",
    "model = BertModel(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([[1,2,3]])\n",
    "out = model(tt, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([[1,2,3,4], [5,6,7,8]]).reshape(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
