{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we want to use a Transformer(Decoder), and if so, how?\n",
    "\n",
    "The default implementation of the Transformer takes **2** parameters (the source sequence and the right-shifted target sequence), i.e. by default it is a translation model (modelling joint probability distributions). Since we only care about generation, what do we do with that?\n",
    "\n",
    "Ideas to try:\n",
    "\n",
    "  1. Instead of the right-shifted traget, provide noise; perhaps noise of different shapes. To be figured out: does the Transformer learn to still reconstruct the sequence? Is this use just a waste of parameters (hence computation)? \n",
    "  \n",
    "  2. Can we somehow invert the TransformerEncoder? That is, learn a function which reconstructs the original sequence from the encoded one, very much like an auto-encoder would work. To be figured out: Does this properly leverage the power of the Transformer?\n",
    "  \n",
    "  3. Train the model to translate into itself, i.e. learn P(X, X) = P(X)? How is this useful though, especially for generation?\n",
    "  \n",
    "  \n",
    "**Generally, we need to figure out how to use the Transformer as a generative model.**\n",
    "Maybe the literature on generative models has inspiration, or even guidance via proper mathematical formalisation of what is to be modeled (formalise modelling problem: random variables, relationships between them, which ones are observable and which ones are not). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Embedding, RNN\n",
    "from torch.nn import Linear, Sigmoid, Softmax\n",
    "from torch.nn import NLLLoss, CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.nn import MSELoss, L1Loss, BCELoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import LM, AggregateHead, ReconstructHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import iter_batches, merge_and_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = 1\n",
    "# ind = 0\n",
    "# def val_in_seq(data):\n",
    "#     return torch.tensor([val in seq for seq in data]).unsqueeze(1).float()\n",
    "# def val_at_index(data):\n",
    "#     return (data[:, ind] == val).unsqueeze(1).float()\n",
    "\n",
    "# def is_sorted(data):\n",
    "#     return ((X.sort(1).values == X).sum(1) == X.shape[1]).unsqueeze(1).float()\n",
    "\n",
    "# def sum_of_seq(data):\n",
    "#     return data.sum(1).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "# task_function = sum_of_seq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, k, V, d = 100, 3, 5, 1\n",
    "X = torch.randint(V, size=(n, k))\n",
    "Y = X[:]\n",
    "\n",
    "eval_X = torch.randint(V, size=(10, k))\n",
    "eval_Y = eval_X[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        vectors = self.enc(inputs)\n",
    "        return self.dec(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LM(V, embed_dim=64, num_layers=2)\n",
    "dec = ReconstructHead(enc)\n",
    "model = Model(enc, dec)\n",
    "\n",
    "\n",
    "losses = []\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optim = SGD(dec.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "\n",
    "model.train()\n",
    "\n",
    "for _ in tqdm(range(2000)):\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    X_ = model(X)\n",
    "    \n",
    "#     print(X_.shape, X.shape, X_.view(-1, 5).shape, X.view(-1).shape)\n",
    "    \n",
    "    loss = criterion(X_.view(-1, 5), X.view(-1))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    losses.append(loss.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)), losses, \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_X_ = model(eval_X)\n",
    "\n",
    "print(eval_X_.argmax(-1), eval_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
