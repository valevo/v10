{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, Embedding, Linear, Softmax, NLLLoss, RNN, ELU\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(batch_size, train_in, train_out, shuffle=False):\n",
    "    if shuffle:\n",
    "        pass\n",
    "    \n",
    "    cur = 0\n",
    "    batch_in, batch_out = train_in[cur:cur+batch_size], train_out[cur:cur+batch_size]\n",
    "    yield batch_in, batch_out\n",
    "    \n",
    "    while batch_in.shape[0] == batch_size:\n",
    "        cur += batch_size\n",
    "        batch_in, batch_out = train_in[cur:cur+batch_size], train_out[cur:cur+batch_size]\n",
    "        if batch_in.numel() > 0:\n",
    "            yield batch_in, batch_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 1\n",
    "ind = 0\n",
    "def val_in_seq(data):\n",
    "    return torch.tensor([val in seq for seq in data]).unsqueeze(1).float()\n",
    "\n",
    "def val_at_index(data):\n",
    "    return (data[:, ind] == val).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "def is_sorted(data):\n",
    "    return ((X.sort(1).values == X).sum(1) == X.shape[1]).unsqueeze(1).float()\n",
    "\n",
    "def sum_of_seq(data):\n",
    "    return data.sum(1).unsqueeze(1).float()\n",
    "\n",
    "\n",
    "task_function = sum_of_seq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, k, V = 100, 3, 5\n",
    "X = torch.randint(V, size=(n, k))\n",
    "Ys = [sum_of_seq(X), val_in_seq(X)]\n",
    "\n",
    "eval_X = torch.randint(V, size=(10, k))\n",
    "eval_Ys = sum_of_seq(eval_X), val_in_seq(eval_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(torch.nn.Module):\n",
    "    def __init__(self, vocab_dim, embed_dim=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.emb = Embedding(vocab_dim, self.embed_dim)\n",
    "        \n",
    "        # nhead needs to divide d_model (embedding dimension)\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=self.embed_dim, nhead=self.embed_dim//2)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x)\n",
    "        out = self.encoder(x_emb)\n",
    "#         out_p = self.sigma(self.linear(out))\n",
    "        return out  # output shape is (x.shape[0], x.shape[1], self.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, lm, out_dim):\n",
    "        super().__init__()\n",
    "        self.lm = lm\n",
    "        self.in_dim = lm.embed_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.linear = Linear(in_features=self.in_dim, out_features=self.out_dim)\n",
    "    \n",
    "    def forward(self, lm_input):\n",
    "        return self.linear(lm(lm_input))\n",
    "    \n",
    "    \n",
    "class AggregateHead(Head):\n",
    "    @staticmethod\n",
    "    def aggr_sum(lm_output):\n",
    "        # lm output shape:(batch, seq_len, transformer_dim)\n",
    "        return lm_output.sum(1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggr_mean(lm_output):\n",
    "        # lm output shape:(batch, seq_len, transformer_dim)\n",
    "        return lm_output.mean(1)\n",
    "    \n",
    "    def __init__(self, lm, aggregate_function):\n",
    "        super().__init__(lm, out_dim=1)\n",
    "        \n",
    "        self.aggr_f = aggregate_function\n",
    "        from torch.nn import Identity\n",
    "        self.final_layer = Identity()\n",
    "        \n",
    "    def forward(self, lm_input):\n",
    "        lm_out = lm(lm_input)\n",
    "        aggr = self.aggr_f(lm_out)\n",
    "        return self.final_layer(self.linear(aggr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hydra(torch.nn.Module):\n",
    "    def __init__(self, *heads):\n",
    "        self.heads = heads\n",
    "        \n",
    "    def forward(self, lm_input):\n",
    "        return [h(lm_input) for h in self.heads]\n",
    "    \n",
    "    def step(self, lm_input, outputs, criteria):\n",
    "        for  h, out, crit in zip(self.heads, outputs, criteria):\n",
    "            pred = h(lm_input)\n",
    "            yield crit(pred, out)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#         loss.backward()\n",
    "#         opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM(V, embed_dim=24)\n",
    "\n",
    "sum_head = AggregateHead(lm, aggregate_function=AggregateHead.aggr_sum)\n",
    "ind_head = AggregateHead(lm, aggregate_function=AggregateHead.aggr_sum)\n",
    "\n",
    "hyd = Hydra(sum_head, ind_head)\n",
    "\n",
    "losses = [[], []]\n",
    "\n",
    "def put_lsss(lss_ls):\n",
    "    for ls, l in zip(losses, lss_ls):\n",
    "        ls.append(l.detach().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in hyd.heads: m.train()\n",
    "\n",
    "crits = [MSELoss()]*2 # may be same object\n",
    "optims = [Adam(sum_head.parameters(), lr=0.01),  Adam(ind_head.parameters(), lr=0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/valentin/.local/lib/python3.6/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n",
      "100%|██████████| 1000/1000 [00:26<00:00, 37.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(1000)):\n",
    "    for o in optims: o.zero_grad()\n",
    "\n",
    "\n",
    "    cur_losses = list(hyd.step(X, Ys, crits))\n",
    "\n",
    "    for l in cur_losses: l.backward()\n",
    "    for o in optims: o.step()\n",
    "        \n",
    "    put_lsss(cur_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ls in losses: plt.plot(range(len(ls)), ls, \"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3, 2],\n",
      "        [3, 4, 0],\n",
      "        [4, 2, 0],\n",
      "        [2, 2, 0],\n",
      "        [0, 2, 4],\n",
      "        [2, 0, 0],\n",
      "        [2, 1, 0],\n",
      "        [4, 4, 2],\n",
      "        [3, 1, 4],\n",
      "        [2, 4, 1]]) tensor([[ 9.4089],\n",
      "        [ 7.2998],\n",
      "        [ 6.2285],\n",
      "        [ 4.1321],\n",
      "        [ 6.2313],\n",
      "        [ 2.0262],\n",
      "        [ 3.0542],\n",
      "        [10.4499],\n",
      "        [ 8.3304],\n",
      "        [ 7.2749]], grad_fn=<AddmmBackward>) tensor([[ 9.],\n",
      "        [ 7.],\n",
      "        [ 6.],\n",
      "        [ 4.],\n",
      "        [ 6.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [10.],\n",
      "        [ 8.],\n",
      "        [ 7.]])\n",
      "\n",
      "\n",
      "tensor([[4, 3, 2],\n",
      "        [3, 4, 0],\n",
      "        [4, 2, 0],\n",
      "        [2, 2, 0],\n",
      "        [0, 2, 4],\n",
      "        [2, 0, 0],\n",
      "        [2, 1, 0],\n",
      "        [4, 4, 2],\n",
      "        [3, 1, 4],\n",
      "        [2, 4, 1]]) tensor([[0.2102],\n",
      "        [0.1378],\n",
      "        [0.1731],\n",
      "        [0.1021],\n",
      "        [0.1699],\n",
      "        [0.0541],\n",
      "        [0.7706],\n",
      "        [0.3077],\n",
      "        [0.8515],\n",
      "        [0.8777]], grad_fn=<AddmmBackward>) tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h, eval_Y in zip(hyd.heads, eval_Ys):\n",
    "    h.eval()\n",
    "    print(eval_X, h(eval_X), eval_Y)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([10.], requires_grad=True)\n",
    "x.backward()\n",
    "\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
